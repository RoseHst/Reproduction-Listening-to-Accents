---
title: "Reproduction of Verbeke und Simon (2023):"
subtitle: "Listening to accents: Comprehensibility, accentedness and intelligibility of native and non-native English speech"
author: Rose Hörsting, Zihang Su, Ali Yıldız
date: last-modified
engine: knitr
bibliography: references.bib
format: 
  html:
    df-print: default
    toc: true
    toc-depth: 3
    fig-width: 8
    fig-height: 6
    number-sections: true
    embed-resources: true
execute:
  warning: false
link-citations: true
number-sections: true
---

```{r, include=FALSE}
#install.packages("tidyverse")
#install.packages("here")
library(tidyverse)
library(here)
```

# About the study/ background

The aim of the study by @verbeke2023listening is to examine the multidialectal listening skills of proficient English learners, i.e. how well English learners understand different accents of English.

-   aim: examine multidialectal listening skills of proficient EFL learners by:

    -   comprehensibility: self-reported ease/ difficulty of understanding a speaker

    -   intelligibility: actual understanding measured by performance in transcription task

    -   accentedness: degree of perceived foreign accent

-   model of "World Englishes": sorting English-speaking and English-unings world into three circles

    -   **Inner circle**: native English-speaking countries

    -   **Outer circle**: history of English occupation (largely colonisation, e.g. India, Nigeria, Kenya)

    -   **Expanding circle**: English used as international language but not official language; not first and dominant language

-   Research questions (@verbeke2023listening: 5-6)

    -   RQ1: How comprehensible are speakers with diﬀerent native and non-native accents of English to EFL learners in higher education and to what extent do the perceived strength of the speaker’s accent and listeners’ familiarity with the speaker’s accent impact on their comprehensibility ratings?

    -   RQ2: How intelligible are speakers with native and non-native accents of English to EFL learners enrolled at an institute of higher education in Flanders?

    -   RQ3: To what extent are EFL learners’ comprehensibility ratings of speakers with native and non-native accents of English related to their intelligibility scores for these speakers?

-   Hypotheses:

    -   listeners’ judgements of comprehensibility vary as function of which circle speakers represent, i.e. speakers with Inner circle accents are more comprehensible than speakers with non-Inner Circle accents

    -   speakers with Expanding Circle accents are slightly easier to understand than speakers with Outer Circle accents, hypothesised to be rated more accented because further removed from expectation

# Method

## Reading in the data

First, we read in the data provided by the authors of the study. The data is available at the Tromsø Repository of Language and Linguistics (<https://dataverse.no/dataset.xhtml?persistentId=doi:10.18710/8F0Q0L>).

```{r read-data}
#| code-fold: true
Stimuli_T2.data <- read.csv(file = here("dataverse_files", "Listening_to_Accents_Stimuli_Task_2.csv"))

ComprAcc.data <- read.csv(file = here("dataverse_files", "Listening_to_Accents_Comprehensibility_Accentedness.csv"))

ComprIntell.data <- read.csv(file = here("dataverse_files", "Listening_to_Accents_Comprehensibility_Intelligibility.csv"))

Intell.data <- read.csv(file = here("dataverse_files", "Listening_to_Accents_Intelligibility.csv"))
```

Convert character variable "Accent" to factor to get its levels

```{r}

Intell.data$Accent <- as.factor(Intell.data$Accent)
levels(Intell.data$Accent)

```

Rename the levels of Accent

```{r}
Intell.data <- Intell.data |> 
    mutate(Accent = recode(Accent,
                                        "ChinEng" = "Chinese English",
                                        "GAE" = "General American English",
                                        "GBE" = "General British English",
                                        "IndEng" = "Indian English",
                           "NBE" = "Newcastle English",
                           "NigEng" = "Nigerian English",
                           "SAE" = "Texan English",
                           "SpanEng" = "Spanish English"))

levels(Intell.data$Accent)


# levels(Intell.data$Accent) <- c("General British English", "General American English", "Newcastle English", "Texan English", "Indian English", "Nigerian English", "Chinese English", "Spanish English")
```

reorder (according to Inner Circle (Standard British - Standard American - Dialect british - Dialect American), Outer circle (Indian English - Nigeran English), Expanding circle (Chinese English, Spanish English); authors' code slighty modified

```{r}
Intell.data$Accent <- factor(Intell.data$Accent, levels = c("General British English", "General American English", "Newcastle English", "Texan English", "Indian English", "Nigerian English", "Chinese English", "Spanish English"))
levels(Intell.data$Accent)
```

# Results

## Intelligibility

Look at absolute frequencies:

```{r}
table(Intell.data$Accent, Intell.data$Accuracy)
```

### Accent

```{r}
#| label: fig-intell
#| tbl-cap: Intelligibility as measured by transcription performance task
ggplot(Intell.data, 
       aes(x=Accent, fill = Accuracy)) +
  geom_bar(position = "fill") +
    labs(x = "Accent",
       y = "Percent") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

As @fig-intell demonstrates, participants performed better than chance for all accents, although there was some variation between languages that match the Circle model. Most errors were made for Nigerian English and Indian English, which belong to the Outer Circle according to @kachru1985standards, i.e. participants had most trouble understanding these accents. Participants had least trouble transcribing General American English & Texan English, i.e. participants understood these accents best.

Notably, there were (significantly) more errors in understanding Standard British English than American English (British English similar to Expanding Circle Accents). For American English, transciption performance for dialect speech (Texan English) was slightly worse than for the Standard variant (though Accuracy was still very high) while for British English, the Newcastle dialect improved intelligibility slightly compared to General british English.

### Self reported familiarity

reorder levels:

```{r}
Intell.data$Familiarity <- factor(Intell.data$Familiarity, levels = c("Very Often", "Often", "Sometimes", "Rarely", "Never"))
```

```{r}
ggplot(Intell.data,
      aes(x=Familiarity, fill = Accuracy)) +
  geom_bar()

ggplot(Intell.data,
      aes(x=Familiarity, fill = Accuracy)) +
  geom_bar(position = "fill")

```

seemingly no correlation.

### Word Type

```{r}
table(Intell.data$Accuracy, Intell.data$Word_Type)
```

```{r}
mosaicplot(Word_Type ~ Accuracy,
           data = Intell.data,
           main = "",
           xlab = "Word Type",
           ylab = "Accuracy",
           col = c("lightblue", "orange"))
```

Function words slightly more easily intelligible but overall very similar

Ordinal data: comprehensibility ratings and accentedness ratings (and familiarity)

# Notes

R-Markdown script provided but takes forever to render (like more than 1 hour) and heats up the system (because it fits several highly complex models)

-   first goal: work with .csv files to reproduce descriptive results
    -   properties of speech samples used for the tasks → tables
    -   comprehensibility ratings; accentedness ratings → violin plots
    -   self-reported familiarity → tables
    -   transcription accuracy (number & proportion of correctly transcribed content and function words of each speaker of English); which types of transcription errors occurred most frequently
    -   self-reported ease of understanding speakers with different accents - match with their actual understanding? (linear correlation?) → scatterplots

# References

::: {#refs}
:::
