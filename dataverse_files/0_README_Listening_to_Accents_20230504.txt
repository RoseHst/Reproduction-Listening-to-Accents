This README file was generated on 2022-05-17 (YYYY-MM-DD) by Gil Verbeke.
Last updated: 2023-05-04.


-------------------
GENERAL INFORMATION
-------------------

// Title of Dataset: Listening to accents: Comprehensibility, accentedness and intelligibility of native and non-native English speech
// DOI: https://doi.org/10.18710/8F0Q0L
// Contact Information
     // Name: Gil Verbeke
     // Institution: Ghent University
     // Email: Gil.Verbeke@UGent.be
     // ORCID: 0000-0002-9491-9557

// Kind of data: See metadata field Kind of Data.
// Date of data collection/generation: See metadata field Date of Collection.
// Geographic location: See metadata section Geographic Coverage.

// Description of dataset: 

Dataset abstract

This dataset contains the results from 33 Flemish English as a Foreign Language (EFL) learners, who were exposed to eight native and non-native accents of English. These participants completed (i) a comprehensibility and accentedness rating task, followed by (ii) an orthographic transcription task. In the first task, listeners were asked to rate eight speakers of English on comprehensibility and accentedness on a nine-point scale (1 = easy to understand/no accent; 9 = hard to understand/strong accent). How Accentedness ratings and listeners' Familiarity with the different accents impacted on their Comprehensibility judgements was measured using a linear mixed-effects model. The orthographic transcription task, then, was used to verify how well listeners actually understood the different accents of English (i.e. intelligibility). To that end, participants' transcription Accuracy was measured as the number of correctly transcribed words and was estimated using a logistic mixed-effects model. Finally, the relation between listeners' self-reported ease of understanding the different speakers (comprehensibility) and their actual understanding of the speakers (intelligibility) was assessed using a linear mixed-effects regression. R code for the data analysis is provided.  


Article abstract

This study investigates how well English as a Foreign Language (EFL) learners report understanding (i.e. comprehensibility) and actually understand (i.e. intelligibility) native and non-native accents of English, and how EFL learners’ self-reported ease of understanding and actual understanding of these accents are aligned. Thirty-three Dutch-speaking EFL learners performed a comprehensibility and accentedness judgement task, followed by an orthographic transcription task. The judgement task elicited listeners’ scalar ratings of authentic speech from eight speakers with traditional Inner, Outer and Expanding Circle accents. The transcription task assessed listeners’ actual understanding of 40 sentences produced by the same eight speakers. Speakers with Inner Circle accents were reported to be more comprehensible than speakers with non-Inner Circle accents, with Expanding Circle speakers being easier to understand than Outer Circle speakers. The strength of a speaker’s accent significantly affected listeners’ comprehensibility ratings. Most speakers were highly intelligible, with intelligibility scores ranging between 79% and 95%. Listeners’ self-reported ease of understanding the speakers in our study generally matched their actual understanding of those speakers, but no correlation between comprehensibility and intelligibility was detected. The study foregrounds the effect of native and non-native accents on comprehensibility and intelligibility, and highlights the importance of multidialectal listening skills.

REFERENCES
----------

Harding, L. (2018). Listening to an unfamiliar accent. In  G. J. Ockey & E. Wagner (Eds.), Assessing L2 listening: Moving towards authenticity (pp. 98-112). John Benjamins Publishing Company. 

Kachru, B. B. (1985). Standards, codification and sociolinguistic realism: The English language in the outer circle. In R. Quirk & H. G. Widdowson (Eds.), English in the world: Teaching and learning the language and literatures (pp. 11-30). Cambridge University Press. 

Kang, O., & Moran, M. (2018). Different varieties of World Englishes: Perceptual judgments and speech characteristics. In G. J. Ockey & E. Wagner (Eds.), Assessing L2 listening: Moving towards authenticity (pp. 113-126). John Benjamins Publishing Company. 

Kang, O., Thomson, R. I., & Moran, M. (2018). Empirical approaches to measuring the intelligibility of different varieties of English in predicting listener comprehension. Language Learning, 68(1), 115–146. 

García Lecumberri, M. L., Cooke, M., & Cutler, A. (2010). Non-native speech perception in adverse conditions: A review. Speech Communication, 52(1), 864–886. 

Mattys, S. L., Davis, M. H., Bradlow, A. R., & Scott, S. K. (2012). Speech recognition in adverse conditions: A review. Language & Cognitive Processes, 27(1), 953–978. 

Munro, M., & Derwing, T. (2020). Foreign accent, comprehensibility and intelligibility, redux. Journal of Second Language Pronunciation, 6(3), 283–309. 

Wagner, E., & Ockey, G. J. (2018). An overview of the use of authentic, real-world spoken texts on L2 listening tests. In  G. J. Ockey & E. Wagner (Eds.), Assessing L2 listening: Moving towards authenticity (pp. 14-28). John Benjamins Publishing Company.



--------------------------
METHODOLOGICAL INFORMATION
--------------------------

1. Speakers

Based on Kachru’s (1985) model of World Englishes, eight male speakers were selected with eight distinct accents of English. For Inner Circle accents, two speakers of British English and American English each were selected: one speaker had a non-regional or acrolectal accent (i.e. General British English and General American English) whereas the other spoke with a regional accent (i.e. Newcastle English, which is a clear representative of Northern British English, and Texan English, falling under Southern American English). An Indian and a Nigerian speaker of English were selected as speakers with Outer Circle accents. Finally, a Chinese and Spanish speaker were the Expanding Circle speakers in our study. Speaker ages ranged between 34 and 88 years (M = 48.4 years, SD = 18.6 years) at the time of recording. Only male speakers were selected to rule out that gender-related differences in voice quality would influence listeners’ perception and the intelligibility of the native and non-native speakers (e.g., Flege et al., 1995; Kraut & Wulff, 2013).

Following Major et al.’s (2002, p. 179) requirements for speaker eligibility, speakers needed to (i) sound conversational, (ii) have mature voice quality and (iii) sound like a genuine speaker of the given variety. The first conversational criterion was met by sampling passages of spoken English from real interviews and talk shows. All speakers were guests invited for interviews or in talk shows, active in the cultural sector, sports or politics, allowing us to trace their age as well as their country and region of origin. The disadvantage of using speakers with a certain fame is that we cannot rule out that some listeners may have recognized speakers’ voices, despite the fact that excerpts were short, decontextualised and that care was taken not to include any excerpts that contained content referring to the speaker’s profession, sector or origin. The second criterion was met because all speakers were in their thirties or older when the interviews took place. To ascertain whether the accents were authentic and sufficiently recognizable (cf. criterion 3), 20 native speakers of English, recruited through Prolific (https://www.prolific.co/), performed an accent verification task. These participants were undergraduate or graduate students, aged between 18 and 25 (M = 21.5 years, SD = 1.8). They were presented with the excerpts from the comprehensibility and accentedness rating task for each speaker of English (cf. Section 4.3.2), and they were asked to identify which English accent they heard in a five-alternative forced-choice task. All speaker accents were correctly identified by at least 16 of the participants, with General British English, Texan English, Indian English, and Nigerian English being correctly recognized by all participants, and General American English and Chinese English by 95% of the participants. We take these results as evidence that the speech samples contained sufficient features for the listeners to recognize the speaker’s accent. 

2. Listeners

Thirty-three Belgian Dutch students (Mage = 18.9 years, SD = 1.3, range = 17-22) with self-reported normal or corrected-to-normal hearing participated in this study. Female participants (n = 27, 82%) outnumbered male participants (n = 6; 18%). All participants were born and had spent most of their childhood in Flanders. They started learning English in a classroom setting at the age of 12 on average (SD = 1 year) and none of them had stayed in an English-speaking country for more than three months. At the time of testing, they were undergraduate students enrolled in the Linguistics and Literature programme at a Flemish university, with English and a second (foreign) language as main subjects. Informed consent was obtained from the participants at the beginning of the survey. As compensation for their time, they received ten euros.

All participants can be expected to have had at least an upper-intermediate level of English (B2) in the Common European Framework of Reference for languages (CEFR) scale (Council of Europe, 2001), since this level is an entry requirement for the English courses the students were taking at the time of testing. Participants were also asked to specifically rate their listening skills: six participants (18%) rated their listening skills in English as intermediate (CEFR equivalent: B1), 16 (49%) as upper-intermediate (CEFR equivalent: B2) and 11 (33%) as advanced (CEFR equivalents: C1-C2). Focusing on intermediate to high proficiency rather than on low proficiency listeners is motivated by the fact that language proficiency has been found to impact on L2 listeners’ ratings of comprehensibility and accentedness (Kang et al., 2019; Ludwig & Mora, 2017; for an exception, see Saito et al., 2019). Specifically, low proficiency listeners (CEFR equivalent: A1-A2) may encounter more difficulties when they are listening to different accents of English and consequently rate the speakers as less comprehensible, because their representations of L2 speech sounds and words are not yet sufficiently developed or detailed to recognize the individual sounds or words in accented speech (see Cutler, 2015; Eger & Reinisch, 2019).

3. Materials

3.1 Questionnaire

A questionnaire was administered to gather information about the sociodemographic and linguistic background of each listener, and about the difficulties that these EFL learners experience when listening in English. Listeners were also asked to indicate how often they were exposed to the eight accents used in the present study on a 5-point scale (1 = never, 5 = very often). We added familiarity as a variable in the questionnaire, because listeners’ linguistic background and prior exposure to a particular accent have been found to affect ratings of comprehensibility and accentedness, as well as intelligibility scores (cf. Section 2).

3.2 Comprehensibility and Accentedness judgement task

Stimuli for the comprehensibility and accentedness judgement task were eight passages of spoken language, one for each of the selected accents of English (cf. Section 4.1; Appendix A). Speech excerpts were drawn from interviews and talk shows, and the topics discussed in those excerpts were diverse: film reviews, fandom, political issues and personal relationships with family and friends. In the selection of the speech samples, care was taken to avoid references to the speaker’s name, country of origin or first language, and exclude the voices of other speakers (e.g., talk show host or interviewer). Following Crowther (2020) and Kang et al. (2018), any instance of backchanneling, false starts, throat clearings and salient background noises were removed from the audio using Praat software (Boersma & Weeninck, 2022; Version 6.2.09). This was done to ensure that speaker fluency in all speech samples was comparable. In all excerpts, the root-mean-square amplitude was scaled to 70 dB to minimize the potential effect of intensity differences on listeners’ judgements. Additionally, we controlled for the total duration, number of syllables and speaking rate to rule out that salient differences between the passages would bias listeners’ comprehensibility and accentedness ratings (see Table 1). Excerpts contained 80 syllables on average (SD = 13), with a mean duration of 17.7 seconds (SD = 2.1 s). Speaking rates, as calculated by the number of syllables per second, ranged between 3.8–5.4 syllables per second (M = 4.5; SD = 0.7). 

Table 1: Overview of the speech sample characteristics used for comprehensibility and accentedness judgements.
-------------------------------------------------------------------------------------
Accent				Duration (s)	Syllables (n)	Syllables per second
-------------------------------------------------------------------------------------	

General British English		16.51		78		4.72
General American English	16.19		87		5.37
Northern British English	16.32		86		5.27
Southern American English	15.56		53		3.41
Indian English			16.87		85		5.04
Nigerian English		21.15		98		4.63
Chinese English			20.69		79		3.82
Spanish English			18.17		71		3.91
				
Mean (SD)			17.68 (2.13)	80 (13)		4.52 (0.73)
-------------------------------------------------------------------------------------
			
3.3 Orthographic Transcription Task

Stimulus materials for the orthographic transcription task were 40 short sentences (i.e. five for each speaker of English) selected from the same talk shows or interviews, but different from the excerpts selected for the comprehensibility and accentedness judgement task, in order to rule out the potential effect of previous exposure (see Appendix B). The disadvantage of using transcription tasks to measure intelligibility is that listeners may recognize and transcribe words they do not actually understand (cf. Munro & Derwing, 2020; Zielinski, 2008). To mitigate the risk of confounding word recognition with intelligibility, each selected sentence contained only moderate to high frequency content words, which were matched as closely as possible in lexical frequency using the SUBTLEX-UK (van Heuven et al., 2014) and SUBTLEX-US (Brysbaert & New, 2009) databases (cf. Table 2).  Using high frequency words has been found to facilitate L2 listening comprehension, because such words can be mapped more easily and more quickly onto L2 listeners’ representations in the mental lexicon (Matthews & Cheng, 2015; White et al., 2013). Similar to the speech samples used for comprehensibility and accentedness rating, sentences were also controlled along several speech dimensions (see Table 2). The average duration of the transcription sentences was 2.45 s (SD = 0.51 s) and sentences had on average 11.8 syllables (SD = 1.95). Speaking rate was held constant between the sentences (M = 4.90, SD = 0.63), and all sentences were scaled to an average intensity of 70 dB to increase inter-stimulus similarity. Multiple one-way ANOVAs and post-hoc pairwise comparisons using Tukey’s HSD test indicated that the speech dimensions of the transcription sentences did not differ significantly. 

Table 2: Features of the speech samples used for intelligibility transcription task per Accent, with GBE = General British English, GAE = General American English, NBE = Northern British English, SAE = Southern American English, IndEng = Indian English, NigEng = Nigerian English, ChinEng = Chinese (accented) English, SpanEng = Spanish (accented) English. 
----------------------------------------------------------------------------------------
Accent	Duration (s)	Syllables (n)	Syllables/s	Target Words	Target Word 										       Frequency (Zipf)
	M   (SD)	M   (SD)	M    (SD)	M    (SD)	M    (SD)
----------------------------------------------------------------------------------------
										
GBE	2.63 (0.64)	13.0 (1.87)	5.05 (0.78)	4.60 (1.14)	4.78 (0.18)
GAE	2.31 (0.41)	11.4 (1.82)	5.02 (0.89)	3.80 (1.10)	4.95 (0.51)
NBE	2.45 (0.32)	11.2 (2.17)	4.58 (0.71)	5.00 (0.71)	5.07 (0.21)
SAE	2.52 (0.55)	11.6 (1.82)	4.66 (0.3)	3.40 (0.89)	4.37 (0.58)
IndEng	2.58 (0.52)	13.2 (1.10)	5.22 (0.61)	4.80 (0.84)	5.06 (0.53)
NigEng	2.40 (0.33)	11.8 (1.48)	4.94 (0.40)	3.80 (0.84)	5.01 (0.22)
ChinEng	2.00 (0.76)	 9.4 (2.41)	4.87 (0.74)	3.40 (0.55)	5.02 (0.41)
SpanEng	2.69 (0.37)	12.6 (1.14)	4.74 (0.64)	3.60 (0.89)	4.83 (0.41)
										
Total	2.45 (0.51)	11.78(1.98)	4.88 (0.63)	4.03 (1.07)	4.89 (0.42)
----------------------------------------------------------------------------------------

----------------------
(*) A standardized Zipf value was calculated for each word based on its proportional frequency per million words (fpmw), because the accuracy of interpreting word-specific fpmws has been shown to be highly contingent on the size of the corpus (van Heuven et al., 2014). The Zipf scale is a logarithmic scale with values ranging from 1, which are low-frequency words, over 6, which are high-frequency lexical words, to 7, which are highly frequent, but often semantically neutral function words such as pronouns and copulas. 
----------------------

4. Procedure

The experimental survey was developed in LimeSurvey (Version 2.73.1). Written on-screen instructions explained that the survey consisted of a questionnaire followed by two listening tasks. All questions and instructions were provided in English to activate an English listening mode (see Grosjean, 1998). Listeners were instructed to test their audio using headphones and they were encouraged to adjust their computer volume to a self-selected comfortable listening level. Participants completed the online experimental survey in a single session in a quiet room of their choice, which lasted on average 30 minutes (SD = 12 minutes). 

In the first part of the survey, listeners completed the questionnaire about their sociodemographic and linguistic background. In the second part, listeners were asked to rate the speech of the eight speakers on comprehensibility and accentedness using nine-point scales. Clear and concise definitions of both terms were provided to the participants. Comprehensibility was defined as how easy or how difficult it is to understand what a speaker is saying (1 = easy to understand; 9 = hard to understand). Accentedness was defined as the degree to which a speaker’s speech sounds different from a listener’s expectation of English (1 = no accent; 9 = strong accent). Unlike in Munro and Derwing’s study (1995), accentedness did not exclusively pertain to foreign accents; we also considered the effect of acrolectal and regional Inner Circle, and Outer and Expanding Circle accents on L2 listening comprehension. The selected speech samples were randomized across all participants and were only played once. After completion of the comprehensibility and accentedness judgement task, listeners could take a self-paced break. In the final task, listeners were presented with 40 short sentences which they needed to transcribe orthographically. They were encouraged to transcribe as many words as possible. Participants heard each sentence only once and stimulus presentation was pseudo-randomized, in that no two sentences of the same speaker could immediately follow each other. After 20 sentences, participants could take a short break. 

5. Analysis

To analyze the comprehensibility and accentedness judgements, a linear mixed-effects regression model was built in R using the lme4 package (Bates et al., 2015) (cf. RQ1), with participants’ Comprehensibility ratings (score from 1 to 9) as the dependent variable. The native or non-native Accents of English (8 accents) and Accentedness ratings (score from 1 to 9), including their interaction, were entered as the fixed effects, with the Comprehensibility ratings for General British English mapped onto the intercept. Familiarity (5 levels of exposure) was also included as a fixed factor, but due to data sparsity, it was recoded as a binary categorical variable: Unfamiliar (exposure frequency: never or rarely) and Familiar (exposure frequency: sometimes, often or very often). Variability between Participants was accounted for through the addition of by-subject random intercepts and slopes. 

Participants’ transcription accuracy in the second task was measured as the number of correctly transcribed words, which we interpreted as a proxy for Intelligibility (cf. RQ2). All words (content and function words) in each stimulus sentence were coded as either correctly or incorrectly transcribed. Transcriptions containing mistakes which could clearly be identified as spelling mistakes were not considered incorrect (e.g., studio audiance for studio audience). Intelligibility was analyzed using a mixed-effects logistic regression model, with transcription Accuracy (correct vs. incorrect) as the dependent variable. Accent (8 accents), Word Type (Content vs. Function word) and Familiarity (Familiar vs. Unfamiliar) were included as fixed factors. Random intercepts were added to the model for Sentences and Items (with Items nested in Sentences), and both random intercepts and slopes were added for Participants. We also analyzed which types of transcription errors the non-native listeners made most frequently. Similar to the taxonomy used in Munro and Derwing (2020), we coded the incorrectly transcribed words for (i) replacements (i.e. one word is substituted for another word, such as Ireland for violent, or industries for businesses), (ii) content word omission (i.e. absence of nouns, adjectives, adverbs and non-auxiliary verbs in the transcriptions), (iii) function word omission (i.e. absence of prepositions, pronouns, particles, determiners and auxiliary verbs in the transcriptions), (iv) word form (e.g., plural noun form instead of singular form). 

Finally, we tested to what extent EFL learners’ comprehensibility ratings can account for their transcription accuracy (cf. RQ3). We hypothesize that if comprehensibility scores are strongly skewed towards the highly comprehensible end of the scale, the intelligibility scores will be high too. To verify this, we built a linear-mixed effects regression model, with the proportion of correctly transcribed words as the outcome variable. Comprehensibility ratings (score from 1 to 9) and Accent (8 accents), including their interaction, were entered as the fixed effects, with the reference level for the intercept set to the comprehensibility ratings for General British English. Variability between Participants was accounted for through the addition of by-subject random intercepts and slopes. 

Statistical analyses and visualizations were performed in R (R Core Team, 2022; Version 4.2.0) with RStudio and are available at https://doi.org/10.18710/8F0Q0L (Author & Author, forthcoming). The following R packages were used: afex (Singmann et al., 2022), car (Fox & Weisberg, 2019), dplyr (Wickham et al., 2021), effects (Fox, 2003; Fox & Weisberg, 2018, 2019), ggeffects (Lüdecke, 2018a), ggplot2 (Wickham, 2016), lattice (Sarkar, 2008), lme4 (Bates et al., 2015), Matrix (Bates & Maechler, 2021), optimx (Nash & Varadhan, 2011; Nash, 2014), sjmisc (Lüdecke, 2018b).

REFERENCES
----------
										
Bates, D., & Maechler, M. (2021). Matrix: Sparse and dense matrix classes and methods. R package version 1.4-0.  https://CRAN.R-project.org/package=Matrix 

Bates, D., Maechler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1–48.

Boersma, P., & Weeninck, D. (2022). Praat: Doing phonetics by computer. In (Version 6.2.09) http://www.praat.org/

Brysbaert, M., & New, B. (2009). Moving beyond Kucera and Francis: a critical evaluation of current word frequency norms and the introduction of a new and improved word frequency measure for American English. Behavior Research Methods, 41(4), 977-990.

Council of Europe. (2001). Common European framework of reference for languages: Learning, teaching, assessment. Cambridge: Press Syndicate of the University of Cambridge. 

Crowther, D. (2020). Rating L2 speaker comprehensibility on monologic vs. interactive tasks. Journal of Second Language Pronunciation, 6(1), 96-121.

Cutler, A. (2015). Representation of second language phonology. Applied Psycholinguistics, 36(1), 115-128.

Derwing, T. M., & Munro, M. J. (2001). What speaking rates do non-native listeners prefer. Applied Linguistics, 22(3), 324-337. 

Eger, N. A., & Reinisch, E. (2019). The role of acoustic cues and listener proficiency in the perception of accent in nonnative sounds. Studies in Second Language Acquisition, 41, 179-200.

Foote, J. A., & Trofimovich, P. (2018). Is It Because of My Language Background? A Study of Language Background Influence on Comprehensibility Judgments. The Canadian Modern Language Review, 74(2), 253-278.

Fox, J., & Weisberg, S. (2018). Visualizing fit and lack of fit in complex regression models with predictor effect plots and partial residuals. Journal of Statistical Software, 87(9), 1-27. 

Fox, J., & Weisberg, S. (2019). An R companion to applied regression (3rd ed.). Thousand Oaks. 

Fox, J. (2003). Effect displays in R for Generalised Linear Models. Journal of Statistical Software, 8(15), 1–27. 

Grosjean, F. (1998). Studying bilinguals: Methodological and conceptual issues. Bilingualism: Language and Cognition, 1, 131–149.

Kachru, B. B. (1985). Standards, codification and sociolinguistic realism: The English language in the outer circle. In R. Quirk & H. G. Widdowson (Eds.), English in the world: Teaching and learning the language and literatures (pp. 11-30). Cambridge University Press. 

Kang, O., Thomson, R. I., & Moran, M. (2018). Empirical Approaches to Measuring the Intelligibility of Different Varieties of English in Predicting Listener Comprehension. Language Learning, 68(1), 115-146.

Kang, O., Thomson, R., & Moran, M. (2019). The Effects of International Accents and Shared First Language on Listening Comprehension Tests. TESOL Quarterly, 53(1), 56-81.

Kraut, R., & Wulff, S. (2013). Foreign-accented speech perception ratings: a multifactorial. Journal of Multilingual and Multicultural Development, 34(3), 249-263.

Lüdecke, D. (2018a). ggeffects: tidy data frames of marginal effects from regression models. Journal of Open Source Software, 3(26), 772. https://doi.org/10.21105/joss.00772 

Lüdecke, D. (2018b). sjmisc: Data and variable transformation functions. Journal of Open Source Software, 3(26), 754. https://doi.org/10.21105/joss.00754 

Ludwig, A., & Mora, J. C. (2017). Processing time and comprehensibility judgments in non-native listeners’ perception of L2 speech. Journal of Second Language Pronunciation, 3(2), 167-198. 

Major, R. C., Fitzmaurice, S. F., Bunta, F., & Balasubramanian, C. (2002). The Effects of Nonnative Accents on Listening Comprehension: Implications for ESL Assessment. TESOL Quarterly, 36(2), 173-190. 

Matthews, J., & Cheng, J. (2015). Recognition of high frequency words from speech as a predictor of L2 listening comprehension. System, 52(1), 1-13.

Munro, M. J. (2017). Dimensions of pronunciation. In O. Kang, R. Thomson, & J. M. Murphy (Eds.), The Routledge handbook of contemporary English pronunciation (pp. 413-431). Routledge. 

Munro, M. J., & Derwing, T. M. (1995). Foreign Accent, Comprehensibility, and Intelligibility in the Speech of Second Language Learners. Language Learning, 45(1), 73-97. 

Munro, M. J., & Derwing, T. M. (2015). Intelligibility in Research and Practice. In M. Reed & J. M. Levis (Eds.), The Handbook of English Pronunciation (pp. 377-396). John Wiley & Sons, Inc. 

Munro, M. J., & Derwing, T. M. (2020). Foreign accent, comprehensibility and intelligibility, redux. Journal of Second Language Pronunciation, 6(3), 283-309.

Nagle, C. L., & Rehman, I. (2021). Doing L2 speech research online: Why and how to collect online ratings data. Studies in Second Language Acquisition, 43(4), 916-939.

Nash, J. C. (2014). On best practice optimization methods in R. Journal of Statistical Software, 60(2), 1–14.

Nash, J. C., & Varadhan, R. (2011). Unifying Optimization algorithms to aid software system users: optimx for R. Journal of Statistical Software, 43(9), 1–14.

Ockey, G. J., & Wagner, E. (2018). Chapter 5. An overview of the issue of using different types of speech varieties as listening inputs in L2 listening assessment. In G. J. Ockey & E. Wagner (Eds.), Assessing L2 Listening (pp. 68-81). John Benjamins Publishing. 

Peterson, G. E., & Barney, H. L. (1952). Control methods used in a study of the vowels. Journal of the Acoustical Society of America, 24(2), 175-184. 

Piske, T., MacKay, I. R. A., & Flege, J. E. (2001). Factors affecting degree of foreign accent in an L2: a review. Journal of Phonetics, 29(1), 191-215.

R Core Team (2021). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/

Saito, K., Tran, M., Suzukida, Y., Sun, H., Magne, V., & Ilkan, M. (2019). How Do Second Language Listeners Perceive the Comprehensibility of Foreign-Accented Speech? Studies in Second Language Acquisition, 41(5), 1133-1149.

Sarkar, D. (2008). Lattice: Multivariate data visualization with R. Springer.

Simpson, A. P. (2001). Dynamic consequences of differences in male and female vocal tract dimensions. The Journal of the Acoustical Society of America, 109, 2153-2164.

Singmann, H., Bolker, B., Westfall, J., Aust, F., & Ben-Shachar, M. S. (2022). afex: Analysis of factorial experiments. R package version 1.1-1. https://CRAN.R-project.org/package=afex  

van Heuven, W. J. B., Mandera, P., Keuleers, E., & Brysbaert, M. (2014). SUBTLEX-UK: A new and improved word frequency database for British English. Quarterly Journal of Experimental Psychology, 67, 1176-1190.

White, K. S., Yee, E., Blumstein, S. E., & Morgan, J. L. (2013). Adults show less sensitivity to phonetic detail in unfamiliar words, too. Journal of Memory and Language, 68, 362-378.

Wickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag. 

Wickham, H., François, R., Henry, L., & Müller, K. (2021). dplyr: A grammar of data manipulation. R package version 1.0.5. https://CRAN.R-project.org/package=dplyr

Zielinski, B. W. (2008). The listener: No longer the silent partner in reduced intelligibility. System, 36(1), 69-84.


--------------------
DATA & FILE OVERVIEW
--------------------
// File List: 

- 0_README_Listening_to_Accents_20230504.txt: README file with general and methodological information about the study, as well as an overview of the data and files.
- Data_Protection_Impact_Assessment.pdf: short assessment of whether the open publication of this dataset may be said to be in line with applicable legal regulations and research-ethical guidelines.   
- Listening_to_Accents_Informed_Consent.pdf: data file, informed consent form, pdf format. 
- Listening_to_Accents_Questionnaire.pdf: data file, sociodemographic and linguistic background questionnaire, pdf format. 
- Listening_to_Accents_Stimuli_Task_1.csv: data file, stimulus materials for the comprehensibility and accentedness judgement task, csv format, "," = separator.
- Listening_to_Accents_Stimuli_Task_2.csv: data file, stimulus materials for the orthographic transcription task, csv format, "," = separator.
- Listening_to_Accents_Pretest.csv: data file, online pretest in which participants were asked to identify the regional and non-native varieties of English used in this study, csv format, "," = separator.
- Listening_to_Accents_Comprehensibility_Accentedness.csv: data file, participants' comprehensibility and accentedness judgements of the eight varieties of English, csv format, "," = separator.
- Listening_to_Accents_Intelligibility.csv: data file, participants' transcription accuracy of the words in the 40 sentences in the orthographic transcription task, csv format, "," = separator.
- Listening_to_Accents_Comprehensibility_Intelligibility.csv: data file, Participants' comprehensibility ratings and transcription accuracy for the correlation analysis, csv format, "," = separator.
- Listening_to_Accents.Rmd: R Notebook with data analysis to replicate the results of Verbeke & Simon (under review). 


----------------------------------------------------------------
DATA-SPECIFIC INFORMATION FOR: Listening_to_Accents_Pretest.csv
----------------------------------------------------------------

Variable	Explanation

1   ID		Unique identified for each line in the dataset. 

2   Participant	Unique identifier for each participant. 

3   Accent	native and non-native accents of English (i.e. "GBE = General British English"; "GAE 		= General American English"; "NBE = Northern British English"; "SAE = Southern 			American English"; "IndEng = Indian English"; "NigEng = Nigerian English; "ChinEng = 		Chinese English"; "SpanEng = Spanish English")

4   Participant_Response	Participants identification response

5   Certainty	Participants' self-reported degree of certainty in identifying an accent of English 		(1 = uncertain; 9 = certain)

6   Familiarity	Participants' self-reported familiarity with the varieties of English, (1 			= unfamiliar; 9 = familiar)

-----------------------------------------------------------------------
DATA-SPECIFIC INFORMATION FOR: Listening_to_Accents_Stimuli_Task_1.csv
-----------------------------------------------------------------------

Variable	Explanation

1   ID		Unique identifier for each line in the dataset. 

2   Accent	native and non-native accents of English (i.e. "GBE = General British English"; "GAE 		= General American English"; "NBE = Northern British English"; "SAE = Southern 			American English"; "IndEng = Indian English"; "NigEng = Nigerian English; "ChinEng = 		Chinese English"; "SpanEng = Spanish English")

3   Sample_Text	Orthographic transcription of the speech sample

4   Duration	Duration of the speech sample in seconds.  

5   Syllables	Number of of syllables in the speech sample.  

6   Rate	Speaking rate, which is measured as the number of syllables per second. 


-----------------------------------------------------------------------
DATA-SPECIFIC INFORMATION FOR: Listening_to_Accents_Stimuli_Task_2.csv
-----------------------------------------------------------------------

Variable	Explanation

1   ID		Unique identifier for each line in the dataset. 

2   Accent	native and non-native accents of English (i.e. "GBE = General British English"; "GAE 		= General American English"; "NBE = Northern British English"; "SAE = Southern 			American English"; "IndEng = Indian English"; "NigEng = Nigerian English; "ChinEng = 		Chinese English"; "SpanEng = Spanish English")

3   Sample_Text	Orthographic transcription of the speech sample

4   Duration	Duration of the speech sample in seconds.  

5   Syllables	Number of of syllables in the speech sample.  

6   Rate	Speaking rate, which is measured as the number of syllables per second. 

7   Frequency	Average lexical frequency of the content words in the speech sample. Frequencies in 		Zipf are taken from the SUBTLEX-UK and SUBTLEX-US databases.

---------------------------------------------------------------------------------------
DATA-SPECIFIC INFORMATION FOR: Listening_to_Accents_Comprehensibility_Accentedness.csv
---------------------------------------------------------------------------------------

Variable	Explanation

1   ID		Unique identifier for each line in the dataset. 

2   Participant	Unique identifier for each participant. 

3   Accent	native and non-native accents of English (i.e. "GBE = General British English"; "GAE 		= General American English"; "NBE = Northern British English"; "SAE = Southern 			American English"; "IndEng = Indian English"; "NigEng = Nigerian English; "ChinEng = 		Chinese English"; "SpanEng = Spanish English")

4   Comprehensibility	Listeners' rating of how comprehensible the speaker is on a 					scale from 1 (= easy to understand) to 9 (= hard to 						understand)

5   Accentedness	Listeners' rating of how strong a speaker's accent is on a 					scale from 1 (= no accent) to 9 (= strong accent)

6   Familiarity	Listeners' familiarity with the sampled varieties of English (i.e. never; rarely; 		sometimes; often; very often)


------------------------------------------------------------------------
DATA-SPECIFIC INFORMATION FOR: Listening_to_Accents_Intelligibility.csv
------------------------------------------------------------------------

Variable	Explanation

1   ID		Unique identifier for each line in the dataset. 

2   Participant	Unique identifier for each participant. 

3   Accent	native and non-native accents of English (i.e. "GBE = General British English"; "GAE 		= General American English"; "NBE = Northern British English"; "SAE = Southern 			American English"; "IndEng = Indian English"; "NigEng = Nigerian English; "ChinEng = 		Chinese English"; "SpanEng = Spanish English")

4   Sentence	Unique identifier for each Sentence.

5   Item	Unique identifier for each Item.

6   Stimulus	Stimulus word in the transcription task.

7   Response	Participants' transcription of the stimulus word.

8   Word_Type	Binary categorical variable: "Content word" vs. "Function word"

9   Accuracy	Accuracy of the transcription. Binary categorical variable: "TRUE" (i.e. correctly 		transcribed) vs. "FALSE" (i.e. incorrectly transcribed)

10   Error_Type	Type of transcription error, including (i) replacements (i.e. a content or function word had been substituted for another word), (ii) content word 	omission (i.e. absence of nouns, adjectives, adverbs and non-auxiliary verbs in the transcriptions), (iii) function word omission (i.e. absence of prepositions, pronouns, particles, determiners and auxiliary verbs in the transcriptions), (iv) word form (e.g., plural form of the noun instead of the singular, incorrect verb tense or verb form, etc.). This results in five categories: "Replacement_CW", "Replacement_FW", "Omission_CW", "Omission_FW" and "Word_form". Missing values, i.e. when the transcription accuracy is TRUE, are indicated by empty cells. 

11  Familiarity	Listeners' familiarity with the sampled varieties of English (i.e. 			never; rarely; sometimes; often; very often)

-----------------------------------------------------------------------------------------
DATA-SPECIFIC INFORMATION FOR: Listening_to_Accents_Comprehensibility_Intelligibility.csv
-----------------------------------------------------------------------------------------

Variable	Explanation

1   ID		Unique identifier for each line in the dataset. 

2   Participant	Unique identifier for each participant. 

3   Accent	native and non-native accents of English (i.e. "GBE = General British English"; "GAE 		= General American English"; "NBE = Northern British English"; "SAE = Southern 			American English"; "IndEng = Indian English"; "NigEng = Nigerian English; "ChinEng = 		Chinese English"; "SpanEng = Spanish English")

4   Comprehensibility	Listeners' rating of how comprehensible the speaker is on a scale from 1 (= easy to understand) to 9 (= hard to understand)

5  Intelligibility	Proportion of correctly transcribed words per Accent. 



// Is this a new version of a previously published dataset? no

--------------------------
SHARING/ACCESS INFORMATION
--------------------------

// Links to publications that cite or use the data: See metadata field Related Publication.
// Recommended citation: See citation generated by repository.


